{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d50d1b4",
   "metadata": {},
   "source": [
    "Load the \"MainProcess.xes\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9942f18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MainProcess.xes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\olive\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "parsing log, completed traces :: 100%|██████████| 301/301 [00:00<00:00, 686.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Imported MainProcess.xes with 301 traces.\n",
      "Number of events: 9471\n",
      "Number of unique activities: 21\n",
      "Unique activities: {'/hbw/store', '/ov/burn', '/dm/cylindrical_drill', '/mm/mill', '/dm/drill', '/pm/punch_recesses', '/wt/pick_up_and_transport', '/pm/punch_gill', '/mm/transport_from_to', '/sm/transport', '/sm/sort', '/pm/punch_ribbing', '/vgr/pick_up_and_transport', '/ov/temper', '/mm/deburr', '/mm/drill', '/hbw/get_empty_bucket', '/dm/lower', '/hw/human_review', '/hbw/unload', '/hbw/store_empty_bucket'}\n",
      "Number of cases: 301\n",
      "First 5 case IDs: ['WF_101_0', 'WF_102_0', 'WF_103_0', 'WF_104_0', 'WF_105_0']\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.algo.discovery.heuristics import algorithm as heuristics_miner\n",
    "from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
    "import pandas as pd\n",
    "\n",
    "# Directory with your .xes files\n",
    "xes_directory = os.path.join(os.getcwd(), \"20130794\", \"Cleaned Event Log\")\n",
    "\n",
    "# Output directory for models or visuals\n",
    "output_directory = os.path.join(os.getcwd(), \"output\")\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Process MainProcess.xes file\n",
    "filename = \"MainProcess.xes\"\n",
    "file_path = os.path.join(xes_directory, filename)\n",
    "print(f\"Processing {filename}\")\n",
    "\n",
    "try:\n",
    "    log = xes_importer.apply(file_path)\n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"Imported {filename} with {len(log)} traces.\")\n",
    "    \n",
    "    # Print important information about the log\n",
    "    print(f\"Number of events: {sum(len(trace) for trace in log)}\")\n",
    "    activities = set(event[\"concept:name\"] for trace in log for event in trace if \"concept:name\" in event)\n",
    "    print(f\"Number of unique activities: {len(activities)}\")\n",
    "    print(f\"Unique activities: {activities}\")\n",
    "    case_ids = [trace.attributes[\"concept:name\"] for trace in log if \"concept:name\" in trace.attributes]\n",
    "    print(f\"Number of cases: {len(case_ids)}\")\n",
    "    print(f\"First 5 case IDs: {case_ids[:5]}\")\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932548e6",
   "metadata": {},
   "source": [
    "Get all the attributes included in this file (\"MainProcess.xes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91ac4541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Attributes of traces:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concept:name</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Attribute Type\n",
       "0  concept:name  str"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Attributes of events:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case:concept:name</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>requested_service_url</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>human_workstation_green_button_pressed</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lifecycle:state</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>response_status_code</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>process_model_id</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>operation_end_time</td>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>time:timestamp</td>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>org:resource</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>planned_operation_time</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>parameters</td>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>unsatisfied_condition_description</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>event_id</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SubProcessID</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>complete_service_time</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>current_task</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>concept:name</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>case</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lifecycle:transition</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>identifier:id</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Attribute      Type\n",
       "0                        case:concept:name       str\n",
       "1                    requested_service_url       str\n",
       "2   human_workstation_green_button_pressed     float\n",
       "3                          lifecycle:state       str\n",
       "4                     response_status_code     float\n",
       "5                         process_model_id       str\n",
       "6                       operation_end_time  datetime\n",
       "7                           time:timestamp  datetime\n",
       "8                             org:resource       str\n",
       "9                   planned_operation_time       str\n",
       "10                              parameters      dict\n",
       "11       unsatisfied_condition_description       str\n",
       "12                                event_id       str\n",
       "13                            SubProcessID       str\n",
       "14                   complete_service_time       str\n",
       "15                            current_task       str\n",
       "16                            concept:name       str\n",
       "17                                    case       str\n",
       "18                    lifecycle:transition       str\n",
       "19                           identifier:id       str"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    # List all attributes of the traces in a table\n",
    "    print(\"\\n\\nAttributes of traces:\\n\")\n",
    "    \n",
    "    trace_attributes = set()\n",
    "    for trace in log:\n",
    "        trace_attributes.update(trace.attributes.keys())\n",
    "        \n",
    "    trace_attr_info = []\n",
    "    for attr in trace_attributes:\n",
    "        attr_type = \"unknown\"\n",
    "        for trace in log:\n",
    "            if attr in trace.attributes:\n",
    "                attr_type = type(trace.attributes[attr]).__name__\n",
    "                break\n",
    "        trace_attr_info.append({\"Attribute\": attr, \"Type\": attr_type})\n",
    "\n",
    "    trace_attr_df = pd.DataFrame(trace_attr_info)\n",
    "    display(trace_attr_df)\n",
    "    # Save the attribute DataFrame to an Excel file in a \"tables\" subfolder\n",
    "    tables_dir = os.path.join(os.getcwd(), \"tables\")\n",
    "    os.makedirs(tables_dir, exist_ok=True)\n",
    "    trace_attr_df.to_excel(os.path.join(tables_dir, \"main_trace_attribute_info.xlsx\"), index=False)\n",
    "    \n",
    "    # List all attributes of the events in a table\n",
    "    print(\"\\n\\nAttributes of events:\\n\")\n",
    "    \n",
    "    event_attributes = set()\n",
    "    for trace in log:\n",
    "        for event in trace:\n",
    "            event_attributes.update(event.keys())\n",
    "\n",
    "    event_attr_info = []\n",
    "    for attr in event_attributes:\n",
    "        attr_type = \"unknown\"\n",
    "        for trace in log:\n",
    "            for event in trace:\n",
    "                if attr in event:\n",
    "                    attr_type = type(event[attr]).__name__\n",
    "                    break\n",
    "            if attr_type != \"unknown\":\n",
    "                break\n",
    "        event_attr_info.append({\"Attribute\": attr, \"Type\": attr_type})\n",
    "\n",
    "    event_attr_df = pd.DataFrame(event_attr_info)\n",
    "    display(event_attr_df)\n",
    "    # Save the attribute DataFrame to an Excel file in a \"tables\" subfolder\n",
    "    tables_dir = os.path.join(os.getcwd(), \"tables\")\n",
    "    os.makedirs(tables_dir, exist_ok=True)\n",
    "    event_attr_df.to_excel(os.path.join(tables_dir, \"main_event_attribute_info.xlsx\"), index=False)\n",
    "except Exception as e:\n",
    "    print(f\"Error processing the log: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4d128",
   "metadata": {},
   "source": [
    "List all the resources of the log in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c92d65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resource</th>\n",
       "      <th>Event Count</th>\n",
       "      <th>Unique Activities</th>\n",
       "      <th>Activities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hbw_2</td>\n",
       "      <td>1581</td>\n",
       "      <td>2</td>\n",
       "      <td>/hbw/store_empty_bucket, /hbw/unload</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hw_1</td>\n",
       "      <td>522</td>\n",
       "      <td>1</td>\n",
       "      <td>/hw/human_review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sm_2</td>\n",
       "      <td>309</td>\n",
       "      <td>2</td>\n",
       "      <td>/sm/sort, /sm/transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dm_2</td>\n",
       "      <td>177</td>\n",
       "      <td>3</td>\n",
       "      <td>/dm/cylindrical_drill, /dm/drill, /dm/lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ov_1</td>\n",
       "      <td>612</td>\n",
       "      <td>2</td>\n",
       "      <td>/ov/burn, /ov/temper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ov_2</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>/ov/burn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pm_1</td>\n",
       "      <td>204</td>\n",
       "      <td>3</td>\n",
       "      <td>/pm/punch_gill, /pm/punch_recesses, /pm/punch_ribbing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wt_2</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>/wt/pick_up_and_transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mm_2</td>\n",
       "      <td>381</td>\n",
       "      <td>4</td>\n",
       "      <td>/mm/deburr, /mm/drill, /mm/mill, /mm/transport_from_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mm_1</td>\n",
       "      <td>576</td>\n",
       "      <td>4</td>\n",
       "      <td>/mm/deburr, /mm/drill, /mm/mill, /mm/transport_from_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vgr_1</td>\n",
       "      <td>1866</td>\n",
       "      <td>1</td>\n",
       "      <td>/vgr/pick_up_and_transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wt_1</td>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "      <td>/wt/pick_up_and_transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sm_1</td>\n",
       "      <td>378</td>\n",
       "      <td>2</td>\n",
       "      <td>/sm/sort, /sm/transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbw_1</td>\n",
       "      <td>873</td>\n",
       "      <td>4</td>\n",
       "      <td>/hbw/get_empty_bucket, /hbw/store, /hbw/store_empty_bucket, /hbw/unload</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vgr_2</td>\n",
       "      <td>885</td>\n",
       "      <td>1</td>\n",
       "      <td>/vgr/pick_up_and_transport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Resource  Event Count  Unique Activities  \\\n",
       "0     hbw_2         1581                  2   \n",
       "1      hw_1          522                  1   \n",
       "2      sm_2          309                  2   \n",
       "3      dm_2          177                  3   \n",
       "4      ov_1          612                  2   \n",
       "5      ov_2          330                  1   \n",
       "6      pm_1          204                  3   \n",
       "7      wt_2          330                  1   \n",
       "8      mm_2          381                  4   \n",
       "9      mm_1          576                  4   \n",
       "10    vgr_1         1866                  1   \n",
       "11     wt_1          447                  1   \n",
       "12     sm_1          378                  2   \n",
       "13    hbw_1          873                  4   \n",
       "14    vgr_2          885                  1   \n",
       "\n",
       "                                                                 Activities  \n",
       "0                                      /hbw/store_empty_bucket, /hbw/unload  \n",
       "1                                                          /hw/human_review  \n",
       "2                                                   /sm/sort, /sm/transport  \n",
       "3                               /dm/cylindrical_drill, /dm/drill, /dm/lower  \n",
       "4                                                      /ov/burn, /ov/temper  \n",
       "5                                                                  /ov/burn  \n",
       "6                     /pm/punch_gill, /pm/punch_recesses, /pm/punch_ribbing  \n",
       "7                                                 /wt/pick_up_and_transport  \n",
       "8                    /mm/deburr, /mm/drill, /mm/mill, /mm/transport_from_to  \n",
       "9                    /mm/deburr, /mm/drill, /mm/mill, /mm/transport_from_to  \n",
       "10                                               /vgr/pick_up_and_transport  \n",
       "11                                                /wt/pick_up_and_transport  \n",
       "12                                                  /sm/sort, /sm/transport  \n",
       "13  /hbw/get_empty_bucket, /hbw/store, /hbw/store_empty_bucket, /hbw/unload  \n",
       "14                                               /vgr/pick_up_and_transport  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    # Set pandas display options for full width\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    pd.set_option('display.width', 0)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "\n",
    "    resources = set()\n",
    "    for trace in log:\n",
    "        for event in trace:\n",
    "            if \"org:resource\" in event:\n",
    "                resources.add(event[\"org:resource\"])\n",
    "\n",
    "    resource_info = []\n",
    "    for resource in resources:\n",
    "        # Find the first SubProcessID for this resource by searching events until found\n",
    "        first_subprocess_id = \"N/A\"\n",
    "        parameters_dict = None\n",
    "        found = False\n",
    "        for trace in log:\n",
    "                for event in trace:\n",
    "                    if event.get(\"org:resource\") == resource:\n",
    "                        if \"SubProcessID\" in event:\n",
    "                            first_subprocess_id = event[\"SubProcessID\"]\n",
    "                            found = True\n",
    "                            break\n",
    "                if found:\n",
    "                    break\n",
    "                \n",
    "        found = False\n",
    "        for trace in log:\n",
    "                for event in trace:\n",
    "                    if event.get(\"org:resource\") == resource:\n",
    "                        if \"parameters\" in event:\n",
    "                            parameters_dict = event[\"parameters\"]\n",
    "                            found = True\n",
    "                            break\n",
    "                if found:\n",
    "                    break\n",
    "        event_count = sum(1 for trace in log for event in trace if event.get(\"org:resource\") == resource)\n",
    "        activities_performed = set(event[\"concept:name\"] for trace in log for event in trace if event.get(\"org:resource\") == resource)\n",
    "        \n",
    "        resource_info.append({\n",
    "            \"Resource\": resource,\n",
    "            \"Event Count\": event_count,\n",
    "            \"Unique Activities\": len(activities_performed),\n",
    "            \"Activities\": \", \".join(sorted(activities_performed)),\n",
    "        })\n",
    "\n",
    "    resource_df = pd.DataFrame(resource_info)\n",
    "    display(resource_df)\n",
    "    # Save the attribute DataFrame to an Excel file in a \"tables\" subfolder\n",
    "    tables_dir = os.path.join(os.getcwd(), \"tables\")\n",
    "    os.makedirs(tables_dir, exist_ok=True)\n",
    "    resource_df.to_excel(os.path.join(tables_dir, \"resources_info.xlsx\"), index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing the log: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0cc698",
   "metadata": {},
   "source": [
    "Load a single subevent log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18723d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0a0a7c16-85d9-48be-a7d5-32931240c337.xes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00, 143.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Imported 0a0a7c16-85d9-48be-a7d5-32931240c337.xes with 1 traces.\n",
      "Number of events: 5\n",
      "Number of unique activities: 5\n",
      "Unique activities: {'transporting the workpiece to the ejection position', 'transporting the workpiece to the mill', 'ejecting the workpiece to the conveyor belt', 'transporting the workpiece to the sorting machine', 'milling the workpiece'}\n",
      "Number of cases: 0\n",
      "First 5 case IDs: []\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Process 0a0a7c16-85d9-48be-a7d5-32931240c337.xes file\n",
    "filename = \"0a0a7c16-85d9-48be-a7d5-32931240c337.xes\"\n",
    "file_path = os.path.join(xes_directory, filename)\n",
    "print(f\"Processing {filename}\")\n",
    "\n",
    "try:\n",
    "    subevent_log = xes_importer.apply(file_path)\n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"Imported {filename} with {len(subevent_log)} traces.\")\n",
    "\n",
    "    # Print important information about the subevent_log\n",
    "    print(f\"Number of events: {sum(len(trace) for trace in subevent_log)}\")\n",
    "    activities = set(event[\"concept:name\"] for trace in subevent_log for event in trace if \"concept:name\" in event)\n",
    "    print(f\"Number of unique activities: {len(activities)}\")\n",
    "    print(f\"Unique activities: {activities}\")\n",
    "    case_ids = [trace.attributes[\"concept:name\"] for trace in subevent_log if \"concept:name\" in trace.attributes]\n",
    "    print(f\"Number of cases: {len(case_ids)}\")\n",
    "    print(f\"First 5 case IDs: {case_ids[:5]}\")\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd166157",
   "metadata": {},
   "source": [
    "List all the attributes in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19cbb508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>operation_end_time</td>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SubProcessID</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stream:datastream</td>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time:timestamp</td>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>org:resource</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>concept:name</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Attribute      Type\n",
       "0  operation_end_time  datetime\n",
       "1        SubProcessID       str\n",
       "2   stream:datastream      dict\n",
       "3      time:timestamp  datetime\n",
       "4        org:resource       str\n",
       "5        concept:name       str"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    # List all attributes in the subevent_log in a table and display nicely in Jupyter Notebook\n",
    "    all_attributes = set()\n",
    "    for trace in subevent_log:\n",
    "        all_attributes.update(trace.attributes.keys())\n",
    "        for event in trace:\n",
    "            all_attributes.update(event.keys())\n",
    "\n",
    "    # Prepare attribute type information\n",
    "    attr_info = []\n",
    "    for attr in all_attributes:\n",
    "        if attr in subevent_log[0].attributes:\n",
    "            attr_type = type(subevent_log[0].attributes[attr]).__name__\n",
    "        elif len(subevent_log[0]) > 0 and attr in subevent_log[0][0]:\n",
    "            attr_type = type(subevent_log[0][0][attr]).__name__\n",
    "        else:\n",
    "            attr_type = \"unknown\"\n",
    "        attr_info.append({\"Attribute\": attr, \"Type\": attr_type})\n",
    "\n",
    "    # Display as a pandas DataFrame\n",
    "    attr_df = pd.DataFrame(attr_info)\n",
    "    display(attr_df)\n",
    "    # Save the attribute DataFrame to an Excel file in a \"tables\" subfolder\n",
    "    tables_dir = os.path.join(os.getcwd(), \"tables\")\n",
    "    os.makedirs(tables_dir, exist_ok=True)\n",
    "    attr_df.to_excel(os.path.join(tables_dir, \"sub_attribute_info.xlsx\"), index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing the subevent_log: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ddbb29",
   "metadata": {},
   "source": [
    "Load the database file with the sensor data and query it using DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c465224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace:SubProcessID</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>operation_end_time</th>\n",
       "      <th>stream:datastream</th>\n",
       "      <th>stream:system</th>\n",
       "      <th>stream:system_type</th>\n",
       "      <th>stream:observation</th>\n",
       "      <th>stream:procedure_type</th>\n",
       "      <th>stream:interaction_type</th>\n",
       "      <th>stream:timestamp</th>\n",
       "      <th>stream:value</th>\n",
       "      <th>sensor_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01b3f449-6b20-49a8-84a9-a7c2f5d680f2</td>\n",
       "      <td>moving towards the oven</td>\n",
       "      <td>wt_1</td>\n",
       "      <td>2021-07-01T10:32:59.282000</td>\n",
       "      <td>2021-07-01T10:33:09.344000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>http://iot.uni-trier.de/FTOnto#OV_1</td>\n",
       "      <td>sosa:Sensor</td>\n",
       "      <td>http://iot.uni-trier.de/FTOnto#OV_1_WT_1_Temperature</td>\n",
       "      <td>stream:continuous</td>\n",
       "      <td>sosa:Observation</td>\n",
       "      <td>2021-07-01T10:32:59.308000</td>\n",
       "      <td>25.037</td>\n",
       "      <td>stream:point</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     trace:SubProcessID             concept:name org:resource  \\\n",
       "0  01b3f449-6b20-49a8-84a9-a7c2f5d680f2  moving towards the oven         wt_1   \n",
       "\n",
       "               time:timestamp          operation_end_time  stream:datastream  \\\n",
       "0  2021-07-01T10:32:59.282000  2021-07-01T10:33:09.344000               <NA>   \n",
       "\n",
       "                         stream:system stream:system_type  \\\n",
       "0  http://iot.uni-trier.de/FTOnto#OV_1        sosa:Sensor   \n",
       "\n",
       "                                     stream:observation stream:procedure_type  \\\n",
       "0  http://iot.uni-trier.de/FTOnto#OV_1_WT_1_Temperature     stream:continuous   \n",
       "\n",
       "  stream:interaction_type            stream:timestamp stream:value  \\\n",
       "0        sosa:Observation  2021-07-01T10:32:59.308000       25.037   \n",
       "\n",
       "     sensor_key  \n",
       "0  stream:point  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import duckdb\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Make sure xes_directory is defined before this line\n",
    "parquet_dir = os.path.join(xes_directory, \"parquet\")\n",
    "\n",
    "# Connect to an in-memory DuckDB instance\n",
    "con = duckdb.connect(database=':memory:')\n",
    "\n",
    "# Collect all .parquet files in the directory\n",
    "parquet_file = os.path.join(parquet_dir, \"all_combined_new.parquet\")\n",
    "\n",
    "# Ensure there are files to process\n",
    "if not os.path.exists(parquet_file):\n",
    "    raise FileNotFoundError(f\"No Parquet file found at {parquet_file}\")\n",
    "\n",
    "# Register all Parquet files as a single virtual table (view)\n",
    "# IMPORTANT: DuckDB's parquet_scan expects a *list of strings* to be passed as a DuckDB list literal\n",
    "# Use array syntax ['file1.parquet', 'file2.parquet', ...]\n",
    "parquet_list_str = f\"'{parquet_file}'\"\n",
    "query = f\"CREATE VIEW sensor_data AS SELECT * FROM parquet_scan([{parquet_list_str}])\"\n",
    "con.execute(query)\n",
    "\n",
    "# Print the number of rows in the sensor_data table\n",
    "if False:\n",
    "    row_count = con.execute(\"SELECT COUNT(*) FROM sensor_data\").fetchone()[0]\n",
    "    print(f\"Number of rows in sensor_data: {row_count}\")\n",
    "\n",
    "# Print column names\n",
    "if False:\n",
    "    info_df = con.execute(\"PRAGMA table_info('sensor_data')\").df()\n",
    "    print(\"\\nColumns and types in sensor_data:\")\n",
    "    print(info_df['name'])\n",
    "\n",
    "# Show a sample of the data\n",
    "if False:\n",
    "    print(\"\\nSample rows from sensor_data:\")\n",
    "    sample_df = con.execute(\"SELECT * FROM sensor_data LIMIT 5\").df()\n",
    "    display(sample_df)\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Enter query here\n",
    "# ------------------------\n",
    "\n",
    "df_sensor_grouped = con.execute(\"\"\"\n",
    "    SELECT \n",
    "    *\n",
    "    FROM sensor_data\n",
    "    WHERE \"stream:observation\" = 'http://iot.uni-trier.de/FTOnto#OV_1_WT_1_Temperature'\n",
    "    AND \"org:resource\" != 'ov_1'\n",
    "    LIMIT 1\n",
    "    \n",
    "\"\"\").df()\n",
    "\n",
    "# ------------------------\n",
    "\n",
    "\n",
    "# Display with full width\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "display(df_sensor_grouped)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e856a9",
   "metadata": {},
   "source": [
    "Analyse some example process from MainProcess file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37033b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb851d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MainProcess.xes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 301/301 [00:00<00:00, 677.33it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Imported MainProcess.xes with 301 traces.\n",
      "First trace case ID: WF_101_0\n",
      "Event 1: concept:name = /hbw/unload, SubProcessID = N/A\n",
      "Event 2: concept:name = /hbw/unload, SubProcessID = 27958fc0-4484-41ff-9260-e76f8a83a7cd\n",
      "Event 3: concept:name = /hbw/unload, SubProcessID = N/A\n",
      "Event 4: concept:name = /vgr/pick_up_and_transport, SubProcessID = N/A\n",
      "Event 5: concept:name = /vgr/pick_up_and_transport, SubProcessID = 4d198444-6633-4218-b1f7-ca67ec666360\n",
      "Event 6: concept:name = /vgr/pick_up_and_transport, SubProcessID = N/A\n",
      "Event 7: concept:name = /hbw/store_empty_bucket, SubProcessID = N/A\n",
      "Event 8: concept:name = /hbw/store_empty_bucket, SubProcessID = e73aa303-98af-407e-be4e-5ebdee33bc4d\n",
      "Event 9: concept:name = /hbw/store_empty_bucket, SubProcessID = N/A\n",
      "Event 10: concept:name = /vgr/pick_up_and_transport, SubProcessID = N/A\n",
      "Event 11: concept:name = /vgr/pick_up_and_transport, SubProcessID = 0e7b5a4c-4c03-47b2-96fd-e401ed7fbca9\n",
      "Event 12: concept:name = /vgr/pick_up_and_transport, SubProcessID = N/A\n",
      "Event 13: concept:name = /ov/burn, SubProcessID = N/A\n",
      "Event 14: concept:name = /ov/burn, SubProcessID = 633d065f-96c0-4c4b-8112-302990575763\n",
      "Event 15: concept:name = /ov/burn, SubProcessID = N/A\n",
      "Event 16: concept:name = /ov/temper, SubProcessID = N/A\n",
      "Event 17: concept:name = /ov/temper, SubProcessID = 27380990-7b3c-4f2e-9475-23b8ca920e73\n",
      "Event 18: concept:name = /ov/temper, SubProcessID = N/A\n",
      "Event 19: concept:name = /wt/pick_up_and_transport, SubProcessID = N/A\n",
      "Event 20: concept:name = /wt/pick_up_and_transport, SubProcessID = 8febb390-19ce-4d63-a018-d9617a8bb1b7\n",
      "Event 21: concept:name = /wt/pick_up_and_transport, SubProcessID = N/A\n",
      "Event 22: concept:name = /mm/mill, SubProcessID = N/A\n",
      "Event 23: concept:name = /mm/mill, SubProcessID = 167db95e-ae8b-4ae8-ac11-055401e11894\n",
      "Event 24: concept:name = /mm/mill, SubProcessID = N/A\n",
      "Event 25: concept:name = /mm/deburr, SubProcessID = N/A\n",
      "Event 26: concept:name = /mm/deburr, SubProcessID = 180236cc-290d-4c7b-ae7c-95ca561e95fe\n",
      "Event 27: concept:name = /mm/deburr, SubProcessID = N/A\n",
      "Event 28: concept:name = /sm/sort, SubProcessID = N/A\n",
      "Event 29: concept:name = /sm/sort, SubProcessID = 16d2bd16-3be9-4daa-a4ad-edb7f5818fcb\n",
      "Event 30: concept:name = /sm/sort, SubProcessID = N/A\n",
      "Event 31: concept:name = /vgr/pick_up_and_transport, SubProcessID = N/A\n",
      "Event 32: concept:name = /vgr/pick_up_and_transport, SubProcessID = 3166d857-c06e-4881-b71b-42d36bf6a33f\n",
      "Event 33: concept:name = /vgr/pick_up_and_transport, SubProcessID = N/A\n",
      "Event 34: concept:name = /hw/human_review, SubProcessID = N/A\n",
      "Event 35: concept:name = /hw/human_review, SubProcessID = a8d0fcdd-46c6-44f8-8b19-cecd803d356f\n",
      "Event 36: concept:name = /hw/human_review, SubProcessID = N/A\n",
      "Event 37: concept:name = /hbw/get_empty_bucket, SubProcessID = N/A\n",
      "Event 38: concept:name = /hbw/get_empty_bucket, SubProcessID = b179f074-238d-4666-b50f-9a8959d0a48e\n",
      "Event 39: concept:name = /hbw/get_empty_bucket, SubProcessID = N/A\n",
      "Event 40: concept:name = /vgr/pick_up_and_transport, SubProcessID = N/A\n",
      "Event 41: concept:name = /vgr/pick_up_and_transport, SubProcessID = 70541c6c-5bd2-4ffe-9bc1-3491f8ab43d0\n",
      "Event 42: concept:name = /vgr/pick_up_and_transport, SubProcessID = N/A\n",
      "Event 43: concept:name = /vgr/pick_up_and_transport, SubProcessID = N/A\n",
      "Event 44: concept:name = /vgr/pick_up_and_transport, SubProcessID = 56ddf674-c704-4981-a081-d9173bb459e1\n",
      "Event 45: concept:name = /vgr/pick_up_and_transport, SubProcessID = N/A\n",
      "Event 46: concept:name = /hbw/store, SubProcessID = N/A\n",
      "Event 47: concept:name = /hbw/store, SubProcessID = dc5fef31-159a-4304-ad2d-70de3cd0d63b\n",
      "Event 48: concept:name = /hbw/store, SubProcessID = N/A\n",
      "\n",
      "---\n",
      "\n",
      "Processing subprocess file: 27958fc0-4484-41ff-9260-e76f8a83a7cd.xes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00, 24.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 27958fc0-4484-41ff-9260-e76f8a83a7cd.xes with 1 traces.\n",
      "Event 1: concept:name = moving towards the slot 0, org:resource = hbw_2\n",
      "Event 2: concept:name = picking up the bucket from the slot, org:resource = hbw_2\n",
      "Event 3: concept:name = transporting the bucket to the conveyor belt, org:resource = hbw_2\n",
      "Event 4: concept:name = dropping off the bucket at the conveyor belt, org:resource = hbw_2\n",
      "Event 5: concept:name = transporting the bucket to the vacuum gripper robot crane jib, org:resource = hbw_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process MainProcess.xes file\n",
    "filename = \"MainProcess.xes\"\n",
    "file_path = os.path.join(xes_directory, filename)\n",
    "print(f\"Processing {filename}\")\n",
    "\n",
    "try:\n",
    "    log = xes_importer.apply(file_path)\n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"Imported {filename} with {len(log)} traces.\")\n",
    "    \n",
    "    \n",
    "    # Display only the concept:name attribute of the events in the first trace\n",
    "    if len(log) > 0:\n",
    "        first_trace = log[0]\n",
    "        print(f\"First trace case ID: {first_trace.attributes.get('concept:name', 'N/A')}\")\n",
    "        for idx, event in enumerate(first_trace):\n",
    "            print(f\"Event {idx+1}: concept:name = {event.get('concept:name', 'N/A')}, SubProcessID = {event.get('SubProcessID', 'N/A')}\")\n",
    "    else:\n",
    "        print(\"Log is empty, no traces to display.\")\n",
    "\n",
    "    print(\"\\n---\\n\")\n",
    "    \n",
    "    first_subprocess_id = \"27958fc0-4484-41ff-9260-e76f8a83a7cd\"\n",
    "    file = first_subprocess_id + \".xes\"\n",
    "    file_path = os.path.join(xes_directory, file)\n",
    "    \n",
    "    print(f\"Processing subprocess file: {file}\")\n",
    "\n",
    "    sub_log = xes_importer.apply(file_path)\n",
    "    print(f\"Imported {file} with {len(sub_log)} traces.\")\n",
    "\n",
    "    # Display only the concept:name attribute of the events in the first trace of the subprocess log\n",
    "    if len(sub_log) > 0:\n",
    "        first_sub_trace = sub_log[0]\n",
    "        for idx, event in enumerate(first_sub_trace):\n",
    "            print(f\"Event {idx+1}: concept:name = {event.get('concept:name', 'N/A')}, org:resource = {event.get('org:resource', 'N/A')}\")\n",
    "    else:\n",
    "        print(\"Subprocess log is empty, no traces to display.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47644653",
   "metadata": {},
   "source": [
    "Analyze Subprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f18c031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#OV_1', 'http://iot.uni-trier.de/FTOnto#OV_1_WT_1_Temperature')\n",
      "  stream:procedure_type = stream:continuous, range: [25.427, 25.427]\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#OV_1', 'http://iot.uni-trier.de/StreamDataAnnotationOnto#OV_1_Property_Current_State')\n",
      "  stream:procedure_type = stream:discrete, values: ['not ready']\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#OV_1', 'http://iot.uni-trier.de/StreamDataAnnotationOnto#OV_1_Property_Current_Task_Elapsed_Seconds_Since_Start')\n",
      "  stream:procedure_type = stream:continuous, range: [3.031237, 5.53083]\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#OV_1_Light_Barrier_5', 'http://iot.uni-trier.de/FTOnto#LightBarrierInterrupted')\n",
      "  stream:procedure_type = stream:binary, values: ['1.0' '0.0']\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#OV_1_Motor_1', 'http://iot.uni-trier.de/FTOnto#MotorSpeed')\n",
      "  stream:procedure_type = stream:continuous, range: [-512.0, -512.0]\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#OV_1_Position_Switch_1', 'http://iot.uni-trier.de/FTOnto#PositionSwitchPressed')\n",
      "  stream:procedure_type = stream:binary, values: ['0.0']\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#OV_1_Position_Switch_2', 'http://iot.uni-trier.de/FTOnto#PositionSwitchPressed')\n",
      "  stream:procedure_type = stream:binary, values: ['1.0' '0.0']\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#OV_1_Valve_7', 'http://iot.uni-trier.de/FTOnto#ValveOpen')\n",
      "  stream:procedure_type = stream:binary, values: ['1.0']\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#OV_1_WT_1_Compressor_8', 'http://iot.uni-trier.de/FTOnto#CompressorPowerLevel')\n",
      "  stream:procedure_type = stream:continuous, range: [512.0, 512.0]\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#OV_1_WT_1_Compressor_8', 'http://iot.uni-trier.de/FTOnto#OV_1_WT_1_Pneumatic_System_Pressure')\n",
      "  stream:procedure_type = stream:continuous, range: [0.363, 0.426]\n"
     ]
    }
   ],
   "source": [
    "df_sensor_grouped = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        *\n",
    "    FROM sensor_data\n",
    "    WHERE \"org:resource\" = 'ov_1'\n",
    "    AND \"concept:name\" = 'transporting the workpiece to the inside of the oven'\n",
    "    AND \"trace:SubProcessID\" = '001618a4-1be3-406c-bd83-ebe5cff5e4f7'\n",
    "    \n",
    "\"\"\").df()\n",
    "\n",
    "grouped = df_sensor_grouped.groupby(['stream:system', 'stream:observation'])\n",
    "\n",
    "for name, group in grouped:\n",
    "    proc_type = group['stream:procedure_type'].iloc[0]\n",
    "    print(f\"\\nGroup: {name}\")\n",
    "    if proc_type == 'stream:continuous':\n",
    "        # Convert stream:value to numeric if possible\n",
    "        vals = pd.to_numeric(group['stream:value'], errors='coerce')\n",
    "        min_val = vals.min()\n",
    "        max_val = vals.max()\n",
    "        print(f\"  stream:procedure_type = stream:continuous, range: [{min_val}, {max_val}]\")\n",
    "    else:\n",
    "        unique_vals = group['stream:value'].unique()\n",
    "        print(f\"  stream:procedure_type = {proc_type}, values: {unique_vals}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4387b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#PM_1', 'http://iot.uni-trier.de/StreamDataAnnotationOnto#PM_1_Property_Current_State')\n",
      "  stream:procedure_type = stream:discrete, values: ['not ready']\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#PM_1', 'http://iot.uni-trier.de/StreamDataAnnotationOnto#PM_1_Property_Current_Task_Elapsed_Seconds_Since_Start')\n",
      "  stream:procedure_type = stream:continuous, range: [0.093731, 124.781221]\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#PM_1_Capacitive_Sensor_6', 'http://iot.uni-trier.de/FTOnto#Electric_Field_Changed')\n",
      "  stream:procedure_type = stream:binary, values: ['0.0' '1.0']\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#PM_1_Capacitive_Sensor_7', 'http://iot.uni-trier.de/FTOnto#Electric_Field_Changed')\n",
      "  stream:procedure_type = stream:binary, values: ['0.0' '1.0']\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#PM_1_Capacitive_Sensor_8', 'http://iot.uni-trier.de/FTOnto#Electric_Field_Changed')\n",
      "  stream:procedure_type = stream:binary, values: ['1.0']\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#PM_1_Light_Barrier_4', 'http://iot.uni-trier.de/FTOnto#LightBarrierInterrupted')\n",
      "  stream:procedure_type = stream:binary, values: ['0.0' '1.0']\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#PM_1_Light_Barrier_5', 'http://iot.uni-trier.de/FTOnto#LightBarrierInterrupted')\n",
      "  stream:procedure_type = stream:binary, values: ['0.0' '1.0']\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#PM_1_Light_Barrier_6', 'http://iot.uni-trier.de/FTOnto#LightBarrierInterrupted')\n",
      "  stream:procedure_type = stream:binary, values: ['nan']\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#PM_1_Light_Barrier_7', 'http://iot.uni-trier.de/FTOnto#LightBarrierInterrupted')\n",
      "  stream:procedure_type = stream:binary, values: ['nan']\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#PM_1_Motor_1', 'http://iot.uni-trier.de/FTOnto#MotorSpeed')\n",
      "  stream:procedure_type = stream:continuous, range: [-512.0, 512.0]\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#PM_1_Motor_2', 'http://iot.uni-trier.de/FTOnto#MotorSpeed')\n",
      "  stream:procedure_type = stream:continuous, range: [0.0, 0.0]\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#PM_1_Motor_3', 'http://iot.uni-trier.de/FTOnto#MotorSpeed')\n",
      "  stream:procedure_type = stream:continuous, range: [0.0, 512.0]\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#PM_1_Position_Switch_1', 'http://iot.uni-trier.de/FTOnto#PositionSwitchPressed')\n",
      "  stream:procedure_type = stream:binary, values: ['0.0' '1.0']\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#PM_1_Position_Switch_2', 'http://iot.uni-trier.de/FTOnto#PositionSwitchPressed')\n",
      "  stream:procedure_type = stream:binary, values: ['0.0' '1.0']\n",
      "\n",
      "Group: ('http://iot.uni-trier.de/FTOnto#PM_1_Sink', 'http://iot.uni-trier.de/FTOnto#NFC_Tag_UID')\n",
      "  stream:procedure_type = stream:discrete, values: ['6cde5431' '6c565831' 'NaT' '7c0d5831' '0cbc5731' '5c645531' '5c865531'\n",
      " 'cc615731' 'ac4f5831' '6cae5731']\n"
     ]
    }
   ],
   "source": [
    "df_sensor_grouped = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        *\n",
    "    FROM sensor_data\n",
    "    WHERE \"org:resource\" = 'pm_1'\n",
    "    AND \"concept:name\" = 'transporting the workpiece to the punch'\n",
    "    \n",
    "\"\"\").df()\n",
    "\n",
    "grouped = df_sensor_grouped.groupby(['stream:system', 'stream:observation'])\n",
    "\n",
    "for name, group in grouped:\n",
    "    proc_type = group['stream:procedure_type'].iloc[0]\n",
    "    print(f\"\\nGroup: {name}\")\n",
    "    if proc_type == 'stream:continuous':\n",
    "        # Convert stream:value to numeric if possible\n",
    "        vals = pd.to_numeric(group['stream:value'], errors='coerce')\n",
    "        min_val = vals.min()\n",
    "        max_val = vals.max()\n",
    "        print(f\"  stream:procedure_type = stream:continuous, range: [{min_val}, {max_val}]\")\n",
    "    else:\n",
    "        unique_vals = group['stream:value'].unique()\n",
    "        print(f\"  stream:procedure_type = {proc_type}, values: {unique_vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1641a042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique directly-follows relations: 38\n",
      "Number of unique concept:name values: 26\n",
      "Directly-follows relations (event1 -> event2):\n",
      "  moving towards the slot 6 -> picking up the bucket from the slot\n",
      "  picking up the bucket from the slot -> transporting the bucket to the conveyor belt\n",
      "  transporting the bucket to the conveyor belt -> dropping off the bucket at the conveyor belt\n",
      "  dropping off the bucket at the conveyor belt -> transporting the bucket to the vacuum gripper robot crane jib\n",
      "  transporting the bucket to the high-bay warehouse crane jib -> transporting the bucket to the high bay warehouse crane jib\n",
      "  transporting the bucket to the high bay warehouse crane jib -> picking up the bucket from the conveyor belt\n",
      "  picking up the bucket from the conveyor belt -> transporting the bucket to the slot 5\n",
      "  transporting the bucket to the slot 5 -> dropping off the bucket at the slot\n",
      "  moving towards the slot 3 -> picking up the bucket from the slot\n",
      "  moving towards the slot 5 -> picking up the bucket from the slot\n",
      "  picking up the bucket from the conveyor belt -> transporting the bucket to the slot 1\n",
      "  transporting the bucket to the slot 1 -> dropping off the bucket at the slot\n",
      "  picking up the bucket from the conveyor belt -> transporting the bucket to the slot 4\n",
      "  transporting the bucket to the slot 4 -> dropping off the bucket at the slot\n",
      "  moving towards the slot 7 -> picking up the bucket from the slot\n",
      "  picking up the bucket from the conveyor belt -> transporting the bucket to the slot 0\n",
      "  transporting the bucket to the slot 0 -> dropping off the bucket at the slot\n",
      "  moving towards the slot 2 -> picking up the bucket from the slot\n",
      "  picking up the bucket from the conveyor belt -> transporting the bucket to the slot 6\n",
      "  transporting the bucket to the slot 6 -> dropping off the bucket at the slot\n",
      "  moving towards the slot 4 -> picking up the bucket from the slot\n",
      "  moving towards the slot 0 -> picking up the bucket from the slot\n",
      "  picking up the bucket from the conveyor belt -> transporting the bucket to the slot 3\n",
      "  transporting the bucket to the slot 3 -> dropping off the bucket at the slot\n",
      "  picking up the bucket from the conveyor belt -> transporting the bucket to the slot 7\n",
      "  transporting the bucket to the slot 7 -> dropping off the bucket at the slot\n",
      "  moving towards the slot 8 -> picking up the bucket from the slot\n",
      "  moving towards the slot 1 -> picking up the bucket from the slot\n",
      "  picking up the bucket from the conveyor belt -> transporting the bucket to the slot 8\n",
      "  transporting the bucket to the slot 8 -> dropping off the bucket at the slot\n",
      "  picking up the bucket from the conveyor belt -> transporting the bucket to the slot 2\n",
      "  transporting the bucket to the slot 2 -> dropping off the bucket at the slot\n",
      "  dropping off the bucket at the slot -> moving towards the slot 6\n",
      "  picking up the bucket from the conveyor belt -> dropping off the bucket at the slot\n",
      "  dropping off the bucket at the slot -> moving towards the slot 8\n",
      "  dropping off the bucket at the slot -> moving towards the slot 4\n",
      "  dropping off the bucket at the slot -> moving towards the slot 5\n",
      "  dropping off the bucket at the slot -> moving towards the slot 0\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "df_sensor_grouped = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        \"trace:SubProcessID\", \"time:timestamp\", \"concept:name\"\n",
    "    FROM sensor_data\n",
    "    WHERE \"org:resource\" = 'hbw_2'\n",
    "      AND \"concept:name\" NOT ILIKE 'calibrating%'\n",
    "    GROUP BY \"trace:SubProcessID\", \"time:timestamp\", \"concept:name\"\n",
    "\"\"\").df()\n",
    "\n",
    "# Group by SubProcessID and collect event names in order\n",
    "subprocess_groups = df_sensor_grouped.groupby('trace:SubProcessID')\n",
    "\n",
    "events = []\n",
    "\n",
    "for sub_id, group in subprocess_groups:\n",
    "    # Sort by timestamp and get event names\n",
    "    event_names = group.sort_values('time:timestamp')['concept:name'].tolist()\n",
    "    # Remove consecutive duplicates\n",
    "    for i in range(1, len(event_names)):\n",
    "        if event_names[i] != event_names[i-1] and (event_names[i-1], event_names[i]) not in events:\n",
    "            events.append((event_names[i-1], event_names[i]))\n",
    "            \n",
    "            \n",
    "print(f\"Total unique directly-follows relations: {len(events)}\")\n",
    "num_concept_names = df_sensor_grouped['concept:name'].nunique()\n",
    "print(f\"Number of unique concept:name values: {num_concept_names}\")\n",
    "print(\"Directly-follows relations (event1 -> event2):\")\n",
    "for e1, e2 in events:\n",
    "    print(f\"  {e1} -> {e2}\")\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
