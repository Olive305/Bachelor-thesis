{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d50d1b4",
   "metadata": {},
   "source": [
    "Load the \"MainProcess.xes\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9942f18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MainProcess.xes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\olive\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "parsing log, completed traces :: 100%|██████████| 301/301 [00:00<00:00, 646.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Imported MainProcess.xes with 301 traces.\n",
      "Number of events: 9471\n",
      "Number of unique activities: 21\n",
      "Unique activities: {'/mm/transport_from_to', '/dm/drill', '/hbw/store_empty_bucket', '/sm/transport', '/ov/temper', '/pm/punch_gill', '/ov/burn', '/hbw/get_empty_bucket', '/dm/lower', '/sm/sort', '/dm/cylindrical_drill', '/mm/drill', '/pm/punch_ribbing', '/vgr/pick_up_and_transport', '/mm/mill', '/hbw/store', '/hbw/unload', '/mm/deburr', '/wt/pick_up_and_transport', '/pm/punch_recesses', '/hw/human_review'}\n",
      "Number of cases: 301\n",
      "First 5 case IDs: ['WF_101_0', 'WF_102_0', 'WF_103_0', 'WF_104_0', 'WF_105_0']\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.algo.discovery.heuristics import algorithm as heuristics_miner\n",
    "from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
    "import pandas as pd\n",
    "\n",
    "# Directory with your .xes files\n",
    "xes_directory = os.path.join(os.getcwd(), \"20130794\", \"Cleaned Event Log\")\n",
    "\n",
    "# Output directory for models or visuals\n",
    "output_directory = os.path.join(os.getcwd(), \"output\")\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Process MainProcess.xes file\n",
    "filename = \"MainProcess.xes\"\n",
    "file_path = os.path.join(xes_directory, filename)\n",
    "print(f\"Processing {filename}\")\n",
    "\n",
    "try:\n",
    "    log = xes_importer.apply(file_path)\n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"Imported {filename} with {len(log)} traces.\")\n",
    "    \n",
    "    # Print important information about the log\n",
    "    print(f\"Number of events: {sum(len(trace) for trace in log)}\")\n",
    "    activities = set(event[\"concept:name\"] for trace in log for event in trace if \"concept:name\" in event)\n",
    "    print(f\"Number of unique activities: {len(activities)}\")\n",
    "    print(f\"Unique activities: {activities}\")\n",
    "    case_ids = [trace.attributes[\"concept:name\"] for trace in log if \"concept:name\" in trace.attributes]\n",
    "    print(f\"Number of cases: {len(case_ids)}\")\n",
    "    print(f\"First 5 case IDs: {case_ids[:5]}\")\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932548e6",
   "metadata": {},
   "source": [
    "Get all the attributes included in this file (\"MainProcess.xes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ac4541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Attributes of traces:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concept:name</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Attribute Type\n",
       "0  concept:name  str"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Attributes of events:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>identifier:id</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>process_model_id</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>operation_end_time</td>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>planned_operation_time</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time:timestamp</td>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>complete_service_time</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>requested_service_url</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>current_task</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>human_workstation_green_button_pressed</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>event_id</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>case:concept:name</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>case</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lifecycle:transition</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>response_status_code</td>\n",
       "      <td>float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>concept:name</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>org:resource</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>unsatisfied_condition_description</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SubProcessID</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>parameters</td>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lifecycle:state</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Attribute      Type\n",
       "0                            identifier:id       str\n",
       "1                         process_model_id       str\n",
       "2                       operation_end_time  datetime\n",
       "3                   planned_operation_time       str\n",
       "4                           time:timestamp  datetime\n",
       "5                    complete_service_time       str\n",
       "6                    requested_service_url       str\n",
       "7                             current_task       str\n",
       "8   human_workstation_green_button_pressed     float\n",
       "9                                 event_id       str\n",
       "10                       case:concept:name       str\n",
       "11                                    case       str\n",
       "12                    lifecycle:transition       str\n",
       "13                    response_status_code     float\n",
       "14                            concept:name       str\n",
       "15                            org:resource       str\n",
       "16       unsatisfied_condition_description       str\n",
       "17                            SubProcessID       str\n",
       "18                              parameters      dict\n",
       "19                         lifecycle:state       str"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    # List all attributes of the traces in a table\n",
    "    print(\"\\n\\nAttributes of traces:\\n\")\n",
    "    \n",
    "    trace_attributes = set()\n",
    "    for trace in log:\n",
    "        trace_attributes.update(trace.attributes.keys())\n",
    "        \n",
    "    trace_attr_info = []\n",
    "    for attr in trace_attributes:\n",
    "        attr_type = \"unknown\"\n",
    "        for trace in log:\n",
    "            if attr in trace.attributes:\n",
    "                attr_type = type(trace.attributes[attr]).__name__\n",
    "                break\n",
    "        trace_attr_info.append({\"Attribute\": attr, \"Type\": attr_type})\n",
    "\n",
    "    trace_attr_df = pd.DataFrame(trace_attr_info)\n",
    "    display(trace_attr_df)\n",
    "    # Save the attribute DataFrame to an Excel file in a \"tables\" subfolder\n",
    "    tables_dir = os.path.join(os.getcwd(), \"tables\")\n",
    "    os.makedirs(tables_dir, exist_ok=True)\n",
    "    trace_attr_df.to_excel(os.path.join(tables_dir, \"main_trace_attribute_info.xlsx\"), index=False)\n",
    "    \n",
    "    # List all attributes of the events in a table\n",
    "    print(\"\\n\\nAttributes of events:\\n\")\n",
    "    \n",
    "    event_attributes = set()\n",
    "    for trace in log:\n",
    "        for event in trace:\n",
    "            event_attributes.update(event.keys())\n",
    "\n",
    "    event_attr_info = []\n",
    "    for attr in event_attributes:\n",
    "        attr_type = \"unknown\"\n",
    "        for trace in log:\n",
    "            for event in trace:\n",
    "                if attr in event:\n",
    "                    attr_type = type(event[attr]).__name__\n",
    "                    break\n",
    "            if attr_type != \"unknown\":\n",
    "                break\n",
    "        event_attr_info.append({\"Attribute\": attr, \"Type\": attr_type})\n",
    "\n",
    "    event_attr_df = pd.DataFrame(event_attr_info)\n",
    "    display(event_attr_df)\n",
    "    # Save the attribute DataFrame to an Excel file in a \"tables\" subfolder\n",
    "    tables_dir = os.path.join(os.getcwd(), \"tables\")\n",
    "    os.makedirs(tables_dir, exist_ok=True)\n",
    "    event_attr_df.to_excel(os.path.join(tables_dir, \"main_event_attribute_info.xlsx\"), index=False)\n",
    "except Exception as e:\n",
    "    print(f\"Error processing the log: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4d128",
   "metadata": {},
   "source": [
    "List all the resources of the log in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c92d65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resource</th>\n",
       "      <th>Event Count</th>\n",
       "      <th>Unique Activities</th>\n",
       "      <th>Activities</th>\n",
       "      <th>First Subprocess ID</th>\n",
       "      <th>Parameter Keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vgr_1</td>\n",
       "      <td>1866</td>\n",
       "      <td>1</td>\n",
       "      <td>/vgr/pick_up_and_transport</td>\n",
       "      <td>0e7b5a4c-4c03-47b2-96fd-e401ed7fbca9</td>\n",
       "      <td>[parameter_start_position, parameter_end_position]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sm_2</td>\n",
       "      <td>309</td>\n",
       "      <td>2</td>\n",
       "      <td>/sm/sort, /sm/transport</td>\n",
       "      <td>722f5091-ed89-45a3-89c7-4962901b6c14</td>\n",
       "      <td>[parameter_start_position, parameter_end_position]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wt_2</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>/wt/pick_up_and_transport</td>\n",
       "      <td>7316381c-127f-43cb-956b-ca72e60bc6ab</td>\n",
       "      <td>[parameter_start_position, parameter_end_position]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ov_2</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>/ov/burn</td>\n",
       "      <td>1ab1350e-cba4-42ea-8efd-a0b01e88380e</td>\n",
       "      <td>[parameter_burn_workpiece_size, parameter_burn_workpiece_thickness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vgr_2</td>\n",
       "      <td>885</td>\n",
       "      <td>1</td>\n",
       "      <td>/vgr/pick_up_and_transport</td>\n",
       "      <td>4d198444-6633-4218-b1f7-ca67ec666360</td>\n",
       "      <td>[parameter_start_position, parameter_end_position]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wt_1</td>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "      <td>/wt/pick_up_and_transport</td>\n",
       "      <td>8febb390-19ce-4d63-a018-d9617a8bb1b7</td>\n",
       "      <td>[parameter_start_position, parameter_end_position]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ov_1</td>\n",
       "      <td>612</td>\n",
       "      <td>2</td>\n",
       "      <td>/ov/burn, /ov/temper</td>\n",
       "      <td>633d065f-96c0-4c4b-8112-302990575763</td>\n",
       "      <td>[parameter_burn_workpiece_size, parameter_burn_workpiece_thickness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dm_2</td>\n",
       "      <td>177</td>\n",
       "      <td>3</td>\n",
       "      <td>/dm/cylindrical_drill, /dm/drill, /dm/lower</td>\n",
       "      <td>ad6c9c0b-f3ba-45e7-b887-b96bf0260887</td>\n",
       "      <td>[parameter_start_position, parameter_end_position]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pm_1</td>\n",
       "      <td>204</td>\n",
       "      <td>3</td>\n",
       "      <td>/pm/punch_gill, /pm/punch_recesses, /pm/punch_ribbing</td>\n",
       "      <td>21559c95-22a5-4c8b-9424-dbbc14a9f63b</td>\n",
       "      <td>[parameter_start_position, parameter_end_position, parameter_quantity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mm_2</td>\n",
       "      <td>381</td>\n",
       "      <td>4</td>\n",
       "      <td>/mm/deburr, /mm/drill, /mm/mill, /mm/transport_from_to</td>\n",
       "      <td>570d0814-988a-4856-bc82-249db6050f5e</td>\n",
       "      <td>[parameter_start_position, parameter_end_position, parameter_burn_workpiece_size, parameter_quantity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mm_1</td>\n",
       "      <td>576</td>\n",
       "      <td>4</td>\n",
       "      <td>/mm/deburr, /mm/drill, /mm/mill, /mm/transport_from_to</td>\n",
       "      <td>167db95e-ae8b-4ae8-ac11-055401e11894</td>\n",
       "      <td>[parameter_start_position, parameter_end_position]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hbw_1</td>\n",
       "      <td>873</td>\n",
       "      <td>4</td>\n",
       "      <td>/hbw/get_empty_bucket, /hbw/store, /hbw/store_empty_bucket, /hbw/unload</td>\n",
       "      <td>b179f074-238d-4666-b50f-9a8959d0a48e</td>\n",
       "      <td>[parameter_hbw_slot, parameter_use_nfc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hw_1</td>\n",
       "      <td>522</td>\n",
       "      <td>1</td>\n",
       "      <td>/hw/human_review</td>\n",
       "      <td>a8d0fcdd-46c6-44f8-8b19-cecd803d356f</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hbw_2</td>\n",
       "      <td>1581</td>\n",
       "      <td>2</td>\n",
       "      <td>/hbw/store_empty_bucket, /hbw/unload</td>\n",
       "      <td>27958fc0-4484-41ff-9260-e76f8a83a7cd</td>\n",
       "      <td>[parameter_hbw_slot, parameter_use_nfc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sm_1</td>\n",
       "      <td>378</td>\n",
       "      <td>2</td>\n",
       "      <td>/sm/sort, /sm/transport</td>\n",
       "      <td>16d2bd16-3be9-4daa-a4ad-edb7f5818fcb</td>\n",
       "      <td>[parameter_use_nfc, parameter_start_position, parameter_end_position, parameter_sorting_machine_ejection_position]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Resource  Event Count  Unique Activities  \\\n",
       "0     vgr_1         1866                  1   \n",
       "1      sm_2          309                  2   \n",
       "2      wt_2          330                  1   \n",
       "3      ov_2          330                  1   \n",
       "4     vgr_2          885                  1   \n",
       "5      wt_1          447                  1   \n",
       "6      ov_1          612                  2   \n",
       "7      dm_2          177                  3   \n",
       "8      pm_1          204                  3   \n",
       "9      mm_2          381                  4   \n",
       "10     mm_1          576                  4   \n",
       "11    hbw_1          873                  4   \n",
       "12     hw_1          522                  1   \n",
       "13    hbw_2         1581                  2   \n",
       "14     sm_1          378                  2   \n",
       "\n",
       "                                                                 Activities  \\\n",
       "0                                                /vgr/pick_up_and_transport   \n",
       "1                                                   /sm/sort, /sm/transport   \n",
       "2                                                 /wt/pick_up_and_transport   \n",
       "3                                                                  /ov/burn   \n",
       "4                                                /vgr/pick_up_and_transport   \n",
       "5                                                 /wt/pick_up_and_transport   \n",
       "6                                                      /ov/burn, /ov/temper   \n",
       "7                               /dm/cylindrical_drill, /dm/drill, /dm/lower   \n",
       "8                     /pm/punch_gill, /pm/punch_recesses, /pm/punch_ribbing   \n",
       "9                    /mm/deburr, /mm/drill, /mm/mill, /mm/transport_from_to   \n",
       "10                   /mm/deburr, /mm/drill, /mm/mill, /mm/transport_from_to   \n",
       "11  /hbw/get_empty_bucket, /hbw/store, /hbw/store_empty_bucket, /hbw/unload   \n",
       "12                                                         /hw/human_review   \n",
       "13                                     /hbw/store_empty_bucket, /hbw/unload   \n",
       "14                                                  /sm/sort, /sm/transport   \n",
       "\n",
       "                     First Subprocess ID  \\\n",
       "0   0e7b5a4c-4c03-47b2-96fd-e401ed7fbca9   \n",
       "1   722f5091-ed89-45a3-89c7-4962901b6c14   \n",
       "2   7316381c-127f-43cb-956b-ca72e60bc6ab   \n",
       "3   1ab1350e-cba4-42ea-8efd-a0b01e88380e   \n",
       "4   4d198444-6633-4218-b1f7-ca67ec666360   \n",
       "5   8febb390-19ce-4d63-a018-d9617a8bb1b7   \n",
       "6   633d065f-96c0-4c4b-8112-302990575763   \n",
       "7   ad6c9c0b-f3ba-45e7-b887-b96bf0260887   \n",
       "8   21559c95-22a5-4c8b-9424-dbbc14a9f63b   \n",
       "9   570d0814-988a-4856-bc82-249db6050f5e   \n",
       "10  167db95e-ae8b-4ae8-ac11-055401e11894   \n",
       "11  b179f074-238d-4666-b50f-9a8959d0a48e   \n",
       "12  a8d0fcdd-46c6-44f8-8b19-cecd803d356f   \n",
       "13  27958fc0-4484-41ff-9260-e76f8a83a7cd   \n",
       "14  16d2bd16-3be9-4daa-a4ad-edb7f5818fcb   \n",
       "\n",
       "                                                                                                        Parameter Keys  \n",
       "0                                                                   [parameter_start_position, parameter_end_position]  \n",
       "1                                                                   [parameter_start_position, parameter_end_position]  \n",
       "2                                                                   [parameter_start_position, parameter_end_position]  \n",
       "3                                                  [parameter_burn_workpiece_size, parameter_burn_workpiece_thickness]  \n",
       "4                                                                   [parameter_start_position, parameter_end_position]  \n",
       "5                                                                   [parameter_start_position, parameter_end_position]  \n",
       "6                                                  [parameter_burn_workpiece_size, parameter_burn_workpiece_thickness]  \n",
       "7                                                                   [parameter_start_position, parameter_end_position]  \n",
       "8                                               [parameter_start_position, parameter_end_position, parameter_quantity]  \n",
       "9                [parameter_start_position, parameter_end_position, parameter_burn_workpiece_size, parameter_quantity]  \n",
       "10                                                                  [parameter_start_position, parameter_end_position]  \n",
       "11                                                                             [parameter_hbw_slot, parameter_use_nfc]  \n",
       "12                                                                                                                  []  \n",
       "13                                                                             [parameter_hbw_slot, parameter_use_nfc]  \n",
       "14  [parameter_use_nfc, parameter_start_position, parameter_end_position, parameter_sorting_machine_ejection_position]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    # Set pandas display options for full width\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    pd.set_option('display.width', 0)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "\n",
    "    resources = set()\n",
    "    for trace in log:\n",
    "        for event in trace:\n",
    "            if \"org:resource\" in event:\n",
    "                resources.add(event[\"org:resource\"])\n",
    "\n",
    "    resource_info = []\n",
    "    for resource in resources:\n",
    "        # Find the first SubProcessID for this resource by searching events until found\n",
    "        first_subprocess_id = \"N/A\"\n",
    "        parameters_dict = None\n",
    "        found = False\n",
    "        for trace in log:\n",
    "                for event in trace:\n",
    "                    if event.get(\"org:resource\") == resource:\n",
    "                        if \"SubProcessID\" in event:\n",
    "                            first_subprocess_id = event[\"SubProcessID\"]\n",
    "                            found = True\n",
    "                            break\n",
    "                if found:\n",
    "                    break\n",
    "                \n",
    "        found = False\n",
    "        for trace in log:\n",
    "                for event in trace:\n",
    "                    if event.get(\"org:resource\") == resource:\n",
    "                        if \"parameters\" in event:\n",
    "                            parameters_dict = event[\"parameters\"]\n",
    "                            found = True\n",
    "                            break\n",
    "                if found:\n",
    "                    break\n",
    "        event_count = sum(1 for trace in log for event in trace if event.get(\"org:resource\") == resource)\n",
    "        activities_performed = set(event[\"concept:name\"] for trace in log for event in trace if event.get(\"org:resource\") == resource)\n",
    "        parameter_keys = list(parameters_dict['children'][i][0] for i in range(len(parameters_dict['children']))) if parameters_dict and 'children' in parameters_dict else []\n",
    "        resource_info.append({\n",
    "            \"Resource\": resource,\n",
    "            \"Event Count\": event_count,\n",
    "            \"Unique Activities\": len(activities_performed),\n",
    "            \"Activities\": \", \".join(sorted(activities_performed)),\n",
    "            \"First Subprocess ID\": first_subprocess_id,\n",
    "            \"Parameter Keys\": parameter_keys\n",
    "        })\n",
    "\n",
    "    resource_df = pd.DataFrame(resource_info)\n",
    "    display(resource_df)\n",
    "    # Save the attribute DataFrame to an Excel file in a \"tables\" subfolder\n",
    "    tables_dir = os.path.join(os.getcwd(), \"tables\")\n",
    "    os.makedirs(tables_dir, exist_ok=True)\n",
    "    resource_df.to_excel(os.path.join(tables_dir, \"resources_info.xlsx\"), index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing the log: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0cc698",
   "metadata": {},
   "source": [
    "Load a single subevent log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18723d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0a0a7c16-85d9-48be-a7d5-32931240c337.xes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00, 145.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Imported 0a0a7c16-85d9-48be-a7d5-32931240c337.xes with 1 traces.\n",
      "Number of events: 5\n",
      "Number of unique activities: 5\n",
      "Unique activities: {'transporting the workpiece to the mill', 'ejecting the workpiece to the conveyor belt', 'milling the workpiece', 'transporting the workpiece to the ejection position', 'transporting the workpiece to the sorting machine'}\n",
      "Number of cases: 0\n",
      "First 5 case IDs: []\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process 0a0a7c16-85d9-48be-a7d5-32931240c337.xes file\n",
    "filename = \"0a0a7c16-85d9-48be-a7d5-32931240c337.xes\"\n",
    "file_path = os.path.join(xes_directory, filename)\n",
    "print(f\"Processing {filename}\")\n",
    "\n",
    "try:\n",
    "    subevent_log = xes_importer.apply(file_path)\n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"Imported {filename} with {len(subevent_log)} traces.\")\n",
    "\n",
    "    # Print important information about the subevent_log\n",
    "    print(f\"Number of events: {sum(len(trace) for trace in subevent_log)}\")\n",
    "    activities = set(event[\"concept:name\"] for trace in subevent_log for event in trace if \"concept:name\" in event)\n",
    "    print(f\"Number of unique activities: {len(activities)}\")\n",
    "    print(f\"Unique activities: {activities}\")\n",
    "    case_ids = [trace.attributes[\"concept:name\"] for trace in subevent_log if \"concept:name\" in trace.attributes]\n",
    "    print(f\"Number of cases: {len(case_ids)}\")\n",
    "    print(f\"First 5 case IDs: {case_ids[:5]}\")\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd166157",
   "metadata": {},
   "source": [
    "List all the attributes in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cbb508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concept:name</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>org:resource</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SubProcessID</td>\n",
       "      <td>str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>operation_end_time</td>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time:timestamp</td>\n",
       "      <td>datetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stream:datastream</td>\n",
       "      <td>dict</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Attribute      Type\n",
       "0        concept:name       str\n",
       "1        org:resource       str\n",
       "2        SubProcessID       str\n",
       "3  operation_end_time  datetime\n",
       "4      time:timestamp  datetime\n",
       "5   stream:datastream      dict"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    # List all attributes in the subevent_log in a table and display nicely in Jupyter Notebook\n",
    "    all_attributes = set()\n",
    "    for trace in subevent_log:\n",
    "        all_attributes.update(trace.attributes.keys())\n",
    "        for event in trace:\n",
    "            all_attributes.update(event.keys())\n",
    "\n",
    "    # Prepare attribute type information\n",
    "    attr_info = []\n",
    "    for attr in all_attributes:\n",
    "        if attr in subevent_log[0].attributes:\n",
    "            attr_type = type(subevent_log[0].attributes[attr]).__name__\n",
    "        elif len(subevent_log[0]) > 0 and attr in subevent_log[0][0]:\n",
    "            attr_type = type(subevent_log[0][0][attr]).__name__\n",
    "        else:\n",
    "            attr_type = \"unknown\"\n",
    "        attr_info.append({\"Attribute\": attr, \"Type\": attr_type})\n",
    "\n",
    "    # Display as a pandas DataFrame\n",
    "    attr_df = pd.DataFrame(attr_info)\n",
    "    display(attr_df)\n",
    "    # Save the attribute DataFrame to an Excel file in a \"tables\" subfolder\n",
    "    tables_dir = os.path.join(os.getcwd(), \"tables\")\n",
    "    os.makedirs(tables_dir, exist_ok=True)\n",
    "    attr_df.to_excel(os.path.join(tables_dir, \"sub_attribute_info.xlsx\"), index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing the subevent_log: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ddbb29",
   "metadata": {},
   "source": [
    "Get all the sensor data included per resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c465224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensor data for Resource: vgr_1 from SubprocessID: 0e7b5a4c-4c03-47b2-96fd-e401ed7fbca9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00, 97.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensor data for Resource: sm_2 from SubprocessID: 722f5091-ed89-45a3-89c7-4962901b6c14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00, 48.44it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensor data for Resource: wt_2 from SubprocessID: 7316381c-127f-43cb-956b-ca72e60bc6ab\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00, 98.37it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensor data for Resource: ov_2 from SubprocessID: 1ab1350e-cba4-42ea-8efd-a0b01e88380e\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00, 35.52it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensor data for Resource: vgr_2 from SubprocessID: 4d198444-6633-4218-b1f7-ca67ec666360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00, 46.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensor data for Resource: wt_1 from SubprocessID: 8febb390-19ce-4d63-a018-d9617a8bb1b7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00, 90.41it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensor data for Resource: ov_1 from SubprocessID: 633d065f-96c0-4c4b-8112-302990575763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00, 102.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensor data for Resource: dm_2 from SubprocessID: ad6c9c0b-f3ba-45e7-b887-b96bf0260887\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00, 52.58it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00, 52.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensor data for Resource: pm_1 from SubprocessID: 21559c95-22a5-4c8b-9424-dbbc14a9f63b\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00, 120.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensor data for Resource: mm_2 from SubprocessID: 570d0814-988a-4856-bc82-249db6050f5e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00, 12.60it/s]\n",
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00, 12.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensor data for Resource: mm_1 from SubprocessID: 167db95e-ae8b-4ae8-ac11-055401e11894\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensor data for Resource: hbw_1 from SubprocessID: b179f074-238d-4666-b50f-9a8959d0a48e\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00, 1531.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensor data for Resource: hw_1 from SubprocessID: a8d0fcdd-46c6-44f8-8b19-cecd803d356f\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00, 24.82it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensor data for Resource: hbw_2 from SubprocessID: 27958fc0-4484-41ff-9260-e76f8a83a7cd\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parsing log, completed traces :: 100%|██████████| 1/1 [00:00<00:00,  8.47it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sensor data for Resource: sm_1 from SubprocessID: 16d2bd16-3be9-4daa-a4ad-edb7f5818fcb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from IPython.display import display\n",
    "\n",
    "# Helper: parse datastream list element into a dict structure\n",
    "def parse_datastream_from_event_xml(event_xml):\n",
    "    # Namespace for XES\n",
    "    ns = {\"xes\": \"http://code.deckfour.org/xes\"}\n",
    "    # datastream list(s) under this event\n",
    "    datastreams = event_xml.findall(\"xes:list[@key='stream:datastream']\", ns)\n",
    "    if not datastreams:\n",
    "        return None\n",
    "\n",
    "    # We'll collect multiple datastream lists if present (usually one). For simplicity,\n",
    "    # if more than one datastream list exists we'll merge their children.\n",
    "    merged = {\"children\": {}}\n",
    "    for datastream in datastreams:\n",
    "        # Each 'point' is a nested list inside the datastream\n",
    "        for idx, point in enumerate(datastream.findall(\"xes:list\", ns)):\n",
    "            # create sensor_point with attributes from the point element (attributes are in the 'stream' namespace)\n",
    "            # the stream namespace is: https://cpee.org/datastream/datastream.xesext\n",
    "            stream_ns = \"https://cpee.org/datastream/datastream.xesext\"\n",
    "            sensor_point = {\n",
    "                \"stream:system\": point.attrib.get(f\"{{{stream_ns}}}system\"),\n",
    "                \"stream:system_type\": point.attrib.get(f\"{{{stream_ns}}}system_type\"),\n",
    "                \"stream:observation\": point.attrib.get(f\"{{{stream_ns}}}observation\"),\n",
    "                \"stream:procedure_type\": point.attrib.get(f\"{{{stream_ns}}}procedure_type\"),\n",
    "                \"stream:interaction_type\": point.attrib.get(f\"{{{stream_ns}}}interaction_type\"),\n",
    "                \"children\": {}\n",
    "            }\n",
    "\n",
    "            # child elements inside the point (like <date key=\"stream:timestamp\" value=\"...\"/>)\n",
    "            for child in point:\n",
    "                # child.attrib typically has 'key' and 'value'\n",
    "                key = child.attrib.get(\"key\")\n",
    "                val = child.attrib.get(\"value\")\n",
    "                if key:\n",
    "                    sensor_point[\"children\"][key] = val\n",
    "\n",
    "            # name the sensor node: use the 'key' attribute of the point element if available,\n",
    "            # otherwise create an indexed name to keep them unique.\n",
    "            sensor_key = point.attrib.get(\"key\", f\"stream:point_{idx}\")\n",
    "            # If same key already exists, create an indexed unique name\n",
    "            if sensor_key in merged[\"children\"]:\n",
    "                # find a unique postfix\n",
    "                i = 1\n",
    "                new_key = f\"{sensor_key}_{i}\"\n",
    "                while new_key in merged[\"children\"]:\n",
    "                    i += 1\n",
    "                    new_key = f\"{sensor_key}_{i}\"\n",
    "                sensor_key = new_key\n",
    "\n",
    "            merged[\"children\"][sensor_key] = sensor_point\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "# Helper: attach parsed sensor dicts to pm4py events (in-memory)\n",
    "def attach_sensor_data_to_pm4py_log(pm4py_log, xes_file_path):\n",
    "    ns = {\"xes\": \"http://code.deckfour.org/xes\"}\n",
    "    tree = ET.parse(xes_file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    xml_traces = root.findall(\".//xes:trace\", ns)\n",
    "\n",
    "    if len(xml_traces) != len(pm4py_log):\n",
    "        print(f\"Warning: number of XML traces ({len(xml_traces)}) != number of pm4py traces ({len(pm4py_log)}). \"\n",
    "              \"We'll attach for the minimum of both and skip extras.\")\n",
    "\n",
    "    n_traces = min(len(xml_traces), len(pm4py_log))\n",
    "\n",
    "    for t_idx in range(n_traces):\n",
    "        xml_trace = xml_traces[t_idx]\n",
    "        pm_trace = pm4py_log[t_idx]\n",
    "\n",
    "        xml_events = xml_trace.findall(\"xes:event\", ns)\n",
    "        pm_events = list(pm_trace)\n",
    "\n",
    "        if len(xml_events) != len(pm_events):\n",
    "            # warn but still attach for min length (common case: may still match)\n",
    "            print(f\"Warning: trace {t_idx} has {len(xml_events)} XML events vs {len(pm_events)} pm4py events. \"\n",
    "                  \"Attaching up to the minimum matched events in order.\")\n",
    "\n",
    "        n_events = min(len(xml_events), len(pm_events))\n",
    "        for e_idx in range(n_events):\n",
    "            xml_event = xml_events[e_idx]\n",
    "            pm_event = pm_events[e_idx]\n",
    "\n",
    "            datastream_dict = parse_datastream_from_event_xml(xml_event)\n",
    "            if datastream_dict:\n",
    "                # attach the Python dict directly into the pm4py event\n",
    "                pm_event[\"stream:datastream\"] = datastream_dict\n",
    "\n",
    "    # returns pm4py_log mutated in place\n",
    "    return pm4py_log\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Main loop (your original structure, adapted)\n",
    "# -------------------------\n",
    "# resource_df is assumed to be defined elsewhere (DataFrame with Resource and First Subprocess ID columns)\n",
    "# xes_directory likewise defined\n",
    "\n",
    "# sensor_dict is used as a mapping from resource -> DataFrame, so initialize as a dict\n",
    "sensor_dict = {}\n",
    "\n",
    "for resource_info in resource_df.itertuples():\n",
    "    resource = resource_info.Resource\n",
    "    # keep your original way to access the First Subprocess ID column (you used _5)\n",
    "    first_subprocess_id = resource_info._5\n",
    "\n",
    "    if first_subprocess_id == \"N/A\":\n",
    "        print(f\"\\nResource: {resource} has no associated SubProcessID.\\n\")\n",
    "        continue\n",
    "\n",
    "    subprocess_filename = f\"{first_subprocess_id}.xes\"\n",
    "    subprocess_file_path = os.path.join(xes_directory, subprocess_filename)\n",
    "\n",
    "    if not os.path.exists(subprocess_file_path):\n",
    "        print(f\"\\nSubprocess file {subprocess_filename} for resource {resource} not found.\\n\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # load with pm4py (this gives us the pm4py event objects)\n",
    "        subprocess_log = xes_importer.apply(subprocess_file_path)\n",
    "\n",
    "        # Parse XES in-memory and attach sensor dicts to pm4py events (no save/reload)\n",
    "        attach_sensor_data_to_pm4py_log(subprocess_log, subprocess_file_path)\n",
    "\n",
    "        print(f\"\\nSensor data for Resource: {resource} from SubprocessID: {first_subprocess_id}\\n\")\n",
    "\n",
    "        # Find the events performed by the current resource and give the sensor data as a table\n",
    "        for trace in subprocess_log:\n",
    "            for event in trace:\n",
    "                # Check if the event is performed by the current resource\n",
    "                if event.get(\"org:resource\") == resource:\n",
    "                    sensor_data = event.get(\"stream:datastream\", {})\n",
    "                    # Check if sensor data exists\n",
    "                    if sensor_data:\n",
    "                        sensor_info = []\n",
    "                        # sensor_data is a dict with 'children' key containing sensor points\n",
    "                        if \"children\" in sensor_data:\n",
    "                            for sensor_name, sensor_point in sensor_data[\"children\"].items():\n",
    "                                # sensor_name is usually 'stream:point' or similar\n",
    "                                if isinstance(sensor_point, dict) and \"children\" in sensor_point:\n",
    "                                    sensor_details = sensor_point[\"children\"]\n",
    "                                    timestamp = sensor_details.get(\"stream:timestamp\")\n",
    "                                    value = sensor_details.get(\"stream:value\")\n",
    "                                    system = sensor_point.get(\"stream:system\")\n",
    "                                    system_type = sensor_point.get(\"stream:system_type\")\n",
    "                                    observation = sensor_point.get(\"stream:observation\")\n",
    "                                    procedure_type = sensor_point.get(\"stream:procedure_type\")\n",
    "                                    interaction_type = sensor_point.get(\"stream:interaction_type\")\n",
    "                                    sensor_info.append({\n",
    "                                        \"Sensor Name\": sensor_name,\n",
    "                                        \"System\": system,\n",
    "                                        \"System Type\": system_type,\n",
    "                                        \"Observation\": observation,\n",
    "                                        \"Procedure Type\": procedure_type,\n",
    "                                        \"Interaction Type\": interaction_type,\n",
    "                                        \"Timestamp\": timestamp,\n",
    "                                        \"Value\": value\n",
    "                                    })\n",
    "\n",
    "                        # display as a pandas DataFrame (empty DataFrame shown if no rows)\n",
    "                        sensor_df = pd.DataFrame(sensor_info)\n",
    "                        if not sensor_df.empty:\n",
    "                            #display(sensor_df)\n",
    "                            sensor_dict[resource] = sensor_df\n",
    "                        else:\n",
    "                            print(f\"Event: {event.get('concept:name')} at {event.get('time:timestamp')} \"\n",
    "                                  f\"has no parsed sensor points.\\n\")\n",
    "                    else:\n",
    "                        print(f\"Event: {event.get('concept:name')} at {event.get('time:timestamp')} \"\n",
    "                              \"has no additional sensor data.\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing subprocess log {subprocess_filename} for resource {resource}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e856a9",
   "metadata": {},
   "source": [
    "Use the sensor dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb851d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(sensor_dict))\n",
    "\n",
    "for resource, sensor_df in sensor_dict.items():\n",
    "    print(f\"\\nSensor data for Resource: {resource}\\n\")\n",
    "    display(sensor_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
